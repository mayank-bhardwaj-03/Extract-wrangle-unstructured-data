{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Assessment 1 Task 1\n",
    "## Task 1: Parsing Raw Text Files\n",
    "#### Student Name: Mayank Bhardwaj\n",
    "#### Student ID: 29325293\n",
    "\n",
    "Date:1/09/2018\n",
    "\n",
    "Environment: Python 3.6.4 and Jupyter notebook\n",
    "Libraries used: \n",
    "* re - This module has been used for the regular expression matching operations.\n",
    "* JSON (JavaScript Object Notation) - This module has been used for the json file. \n",
    "\n",
    "## 1. Introduction\n",
    "* In this assessment, we have analyze the data from an unstructured text file which contains job postings\n",
    "* Each data-set contains information about the job advertisements, e.g., job title, job description, start date, required     qualifications.\n",
    "* We have extracted the data from the given file and transform the data to XML and JSON formats in much more readable         formats.We have to perform following task in order to obtain the XML and JSON file:\n",
    "    * Firstly, read the file and seprate the each job listing with the help of an efficient regex in order to extract the each listing data from the file.\n",
    "    * After that with the help of regex seprate the data from the individual tags and store in the list.\n",
    "    * last step is to convert the data in list into the xml format and JSON format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reading the data\n",
    "* We have read the data in the infile and store in text variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('.\\\\29325293.dat') as infile:\n",
    "    text=infile.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Extracting the data from the file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Identifying and seprate data\n",
    "* We have used the regex r'^(?:ID:)(?:.*?)(?:----------+)' to find all the id and seprate, then store in the list str1.\n",
    "* r'^(?:ID:)(?:.*?)(?:----------+)'\n",
    "    * \twith the beginning of the string as ID and ending with ---------------+ , this regex will find each listing and put it in the string(str1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = re.findall(r'^(?:ID:)(?:.*?)(?:----------+)', text,re.DOTALL|re.MULTILINE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Identifying all the tags in the files.\n",
    "\n",
    "* str_jobid = '(^ID:[ ]?)'\n",
    "    * In this firstly the beginning of string is ID:(space) and ? represent one or more occurrence.\n",
    "* str_joblocation= '([A-Z_]*(?:loc)[A-Z]*:)'\n",
    "    * In this firstly the beginning of string can be a-z or _ can appear 0 or many times.Then we have created the non capturing group and we have to find loc and it should followed by a-z and must end with':'.\n",
    "str_jobtitle= '(^(?:j?o?b?_? ?ti?t?l?e?s?):)'\n",
    "    *  In this firstly the beginning of string can be each character of job_titles will appear either zero or one time and  must end with':'.\n",
    "* str_jobsalary= '([A-Z_]*(?:al|remu)[A-Z]*: )'\n",
    "     * In this firstly the beginning of string can be a-z or _ can appear 0 or many times.Then we have created the non capturing group and we have to find al or remu and it should followed by a-z and must end with':'.\n",
    "* str_requal= '([A-Z_ ]*(?:qual)[A-Z]*:)'\n",
    "    * In this firstly the beginning of string can be a-z or _or space can appear 0 or many times.Then we have created the non capturing group and we have to find qual and it should followed by a-z and must end with':'. \n",
    "* str_startdate= '([A-Z_ ]*(?:da)[A-Z]*:)'\n",
    "    * In this firstly the beginning of string can be a-z or _ or space can appear 0 or many times.Then we have created the non capturing group and we have to find da and it should followed by a-z and must end with':'.\n",
    "* str_jobresp= '([A-Z_ ]*(?:resp)[A-Z]*:)'\n",
    "    * In this firstly the beginning of string can be a-z or _ can appear 0 or many times.Then we have created the non capturing group and we have to find resp and it should followed by a-z and must end with':'.\n",
    "* str_abtcompny= '([A-Z_ ]*(?:about|info)[A-Z ]*:)'\n",
    "    * In this firstly the beginning of string can be a-z or _ or space can appear 0 or many times.Then we have created the non capturing group and we have to find about or info and it should followed by a-z and must end with':'.\n",
    "* str_jobproc= '([A-Z_ ]*(?:proc)[A-Z ]*:)'\n",
    "    * In this firstly the beginning of string can be a-z or _ can appear 0 or many times.Then we have created the non capturing group and we have to find proc and it should followed by a-z and must end with':'.\n",
    "* str_deadline= '([A-Z_]*(?:dead|application)[A-Z_ ]*:)'\n",
    "    * In this firstly the beginning of string can be a-z or _ can appear 0 or many times.Then we have created the non capturing group and we have to find dead or application and it should followed by a-z and must end with':'.\n",
    "* str_jobdesc= '([A-Z_ ]*(?:desc)[A-Z]*:)'\n",
    "    * In this firstly the beginning of string can be a-z or _ can appear 0 or many times.Then we have created the non capturing group and we have to find desc and it should followed by a-z and must end with':'.\n",
    "* str_endline= '(-------------+)'\n",
    "    * it find the end of the resume which is ------------."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All regex has been defined to capture the u=individual tags.\n",
    "str_jobid = '(^ID:[ ]?)'\n",
    "str_joblocation= '(^[A-Z_]*(?:loc)[A-Z]*:)'\n",
    "str_jobtitle= '(^(?:j?o?b?_? ?ti?t?l?e?s?):)'\n",
    "str_jobsalary= '(^[A-Z_]*(?:al|remu)[A-Z]*: )'\n",
    "str_requal= '(^[A-Z_ ]*(?:qual)[A-Z]*:)'\n",
    "str_startdate= '(^[A-Z_ ]*(?:da)[A-Z_]*:)'\n",
    "str_jobresp= '(^[A-Z_ ]*(?:resp)[A-Z]*:)'\n",
    "str_abtcompny= '(^[A-Z_ ]*(?:about|info)[A-Z ]*:)'\n",
    "str_jobproc= '(^[A-Z_ ]*(?:proc)[A-Z ]*:)'\n",
    "str_deadline= '(^[A-Z_]*(?:d[ead_]*?l)[A-Z ]*: )'\n",
    "str_jobdesc= '(^[A-Z_ ]*(?:desc)[A-Z]*:)'\n",
    "str_endline= '(-------------+)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Making list of all the tags in the files.\n",
    "* List_Reg contains all the tags used in the job listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_reg=[str_jobid,str_joblocation,str_jobtitle,str_jobsalary,\n",
    "          str_requal,str_startdate,str_jobresp,str_abtcompny,\n",
    "          str_jobproc,str_deadline,str_jobdesc,str_endline]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Create XML and Json files.\n",
    "* We have created the 29325293.xml file and 29325293.json file to store the job listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file = open('29325293.xml','w')  # xml file open\n",
    "json_file = open('29325293.json','w')    # json file open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Seperate data into individual tags.\n",
    "* Below is the function defined to extract the data from the listing into individual tags and extract the data between the two expression with the help of grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_part(exp,each): # 'exp' is expression which has to be pass and 'each' work as a individual group in list_reg\n",
    "    length_group_2 = 0\n",
    "    reg = ''\n",
    "    for each_exp in list_reg:  # Iterate in the list of regex.\n",
    "\n",
    "        regex = (exp +'(.*?)'+each_exp) \n",
    "        \n",
    "        str_job = re.search(regex,each, re.DOTALL|re.MULTILINE|re.IGNORECASE) # Finds the data between two tags.\n",
    "        \n",
    "        if str_job != None :\n",
    "            group_2 = str_job.group(2)  # extracting the group 2 data\n",
    "\n",
    "\n",
    "            if length_group_2 == 0  :\n",
    "                length_group_2 = len(group_2)  \n",
    "                reg = group_2\n",
    "            # extracting the length of data if its smallest of all than take the data between two tags.\n",
    "            elif len(group_2) < length_group_2 and len(group_2)!= 0:\n",
    "                length_group_2 = len(group_2)\n",
    "                reg = group_2\n",
    "\n",
    "    return (reg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Write the XML and JSON files.\n",
    "* Below is the loop running for the each list and extracting the data between the tags and write it in XML. In addition to this, we have also created json dict which hepls in dumping data into JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_data = []\n",
    "\n",
    "for each in str1:  # running the loop for each job listing.\n",
    "        json_dict={}\n",
    "        \n",
    "        #group1(jobid)\n",
    "        reg=regex_part(str_jobid,each) # calling the regex_part function\n",
    "        job_id = reg.strip('\\n')\n",
    "        xml_file.write('<listings>\\n') # writing the xml file\n",
    "        xml_file.write('\\t'+'<listing id='+job_id+'>'+'\\n')\n",
    "        json_dict['id'] = job_id # storing in the json dict for json file\n",
    "        \n",
    "        #group2(title)\n",
    "        reg=regex_part(str_jobtitle, each) # calling the regex_part function\n",
    "        if reg in('',' ','\\n'):\n",
    "            jobtitle = 'N.A.'\n",
    "        else:    \n",
    "            jobtitle = reg.strip('\\n')\n",
    "            jobtitle = jobtitle.replace('\\n', ' ')\n",
    "        \n",
    "        xml_file.write('\\t'+'<title>\\n'+'\\t\\t'+ jobtitle+'\\n') # writing the xml file\n",
    "        xml_file.write('\\t'+'</title>'+'\\n')\n",
    "        json_dict['title'] = jobtitle # storing in the json dict for json file\n",
    "        \n",
    "        #group3(location)\n",
    "        reg=regex_part(str_joblocation, each) # calling the regex_part function\n",
    "        if reg in('',' ','\\n'):\n",
    "            joblocation = 'N.A.'\n",
    "        else:    \n",
    "            joblocation = reg.strip('\\n')\n",
    "            joblocation = joblocation.replace('\\n', ' ')\n",
    "        \n",
    "        xml_file.write('\\t'+'<location>'+joblocation+'</location>\\n') # writing the xml file\n",
    "        json_dict['location'] = joblocation # storing in the json dict for json file\n",
    "        \n",
    "        #group4(job_description)\n",
    "        reg=regex_part(str_jobdesc, each)\n",
    "        \n",
    "        if reg in('',' ','\\n'):\n",
    "            jobdesc = 'N.A.'\n",
    "        else:    \n",
    "            jobdesc = reg\n",
    "            jobdesc = jobdesc.replace('\\n', ' ')\n",
    "        \n",
    "        xml_file.write('\\t'+'<job_description>\\n'+'\\t\\t'+ '<description>\\n'+'\\t\\t\\t'+ jobdesc + '\\n')\n",
    "        xml_file.write('\\t\\t'+ '</description>\\n'+'\\t'+'</job_description>'+'\\n')\n",
    "        json_dict['job_description'] = {'description': jobdesc}\n",
    "        \n",
    "        #group5(job_responsibilities)\n",
    "        reg=regex_part(str_jobresp, each)\n",
    "        \n",
    "        if reg in('',' ','\\n'):\n",
    "            jobresp1 = ['N.A.']\n",
    "        else:    \n",
    "            jobresp1 = reg.split('- ')\n",
    "        xml_file.write('\\t'+'<job_responsibilities>\\n') # writing the xml file\n",
    "        \n",
    "        for i in range(len(jobresp1)):\n",
    "            jobresp1[i] = jobresp1[i].strip(' ').replace('\\n', ' ')\n",
    "            jobresp1[i] = jobresp1[i].strip('\\n')\n",
    "            \n",
    "        if (' ') in jobresp1:\n",
    "            jobresp1.remove(' ')\n",
    "        elif ('\\n') in jobresp1:\n",
    "            jobresp1.remove('\\n')\n",
    "        elif ('') in jobresp1:\n",
    "            jobresp1.remove('')\n",
    "        \n",
    "        for i in range(len(jobresp1)):\n",
    "            if jobresp1[i] not in (' ', '\\n', '\\n ', ''): \n",
    "                jobresp = jobresp1[i]      \n",
    "                xml_file.write('\\t\\t'+ '<responsibilities>\\n'+'\\t\\t\\t'+ jobresp) # writing the xml file\n",
    "                xml_file.write('\\n\\t\\t'+ '</responsibilities>\\n')\n",
    "                \n",
    "        xml_file.write('\\t''</job_responsibilities>'+'\\n')  \n",
    "        json_dict['job_responsibilities'] = {'responsibility': jobresp1} # storing in the json dict for json file\n",
    "        \n",
    "        #group6(required_qualifications)\n",
    "        reg=regex_part(str_requal, each)\n",
    "        \n",
    "        if reg in('',' ','\\n'):\n",
    "            requal1 = ['N.A.']\n",
    "        else:    \n",
    "            requal1 = reg.split('- ')\n",
    "        xml_file.write('\\t'+'<required_qualifications>\\n') # writing the xml file\n",
    "                      \n",
    "        for i in range(len(requal1)):\n",
    "            requal1[i] = requal1[i].strip(' ').replace('\\n', ' ')\n",
    "            requal1[i] = requal1[i].strip('\\n')\n",
    "            \n",
    "        if (' ') in requal1:\n",
    "            requal1.remove(' ')\n",
    "        elif ('\\n') in requal1:\n",
    "            requal1.remove('\\n')\n",
    "        elif ('') in requal1:\n",
    "            requal1.remove('')\n",
    "            \n",
    "        for i in range(len(requal1)):   \n",
    "            if requal1[i] not in (' ', '\\n', '\\n ', ''): \n",
    "                requal = requal1[i]      \n",
    "                xml_file.write('\\t\\t'+ '<qualifications>\\n'+'\\t\\t\\t'+ requal) \n",
    "                xml_file.write('\\n\\t\\t'+ '<qualifications>\\n')\n",
    "                \n",
    "        xml_file.write('\\t''</required_qualifications>'+'\\n')  # writing the xml file\n",
    "        json_dict['required_qualifications'] = {'qualification': requal1} # storing in the json dict for json file\n",
    "        \n",
    "        #group7(salary)\n",
    "        reg=regex_part(str_jobsalary, each)\n",
    "        if reg in('',' ','\\n'):\n",
    "            jobsalary = 'N.A.'\n",
    "        else:    \n",
    "            jobsalary = reg.strip('\\n')\n",
    "            jobsalary = jobsalary.replace('\\n', ' ')\n",
    "        \n",
    "        xml_file.write('\\t'+'<salary>'+jobsalary+'</salary>\\n') # writing the xml file\n",
    "        json_dict['salary'] = jobsalary # storing in the json dict for json file\n",
    "        \n",
    "        #group8(application_procedure)\n",
    "        reg=regex_part(str_jobproc, each)\n",
    "        if reg in('',' ','\\n'):\n",
    "            jobproc = 'N.A.'\n",
    "        else:    \n",
    "            jobproc = reg.strip('\\n')\n",
    "            jobproc = jobproc.replace('\\n', ' ')\n",
    "        \n",
    "        xml_file.write('\\t'+'<application_procedure>'+jobproc+'</application_procedure>\\n')\n",
    "        json_dict['application_procedure'] = jobproc # storing in the json dict for json file\n",
    "        \n",
    "        #group9(start_date)\n",
    "        reg=regex_part(str_startdate, each)\n",
    "        if reg in('',' ','\\n'):\n",
    "            startdate = 'N.A.'\n",
    "        else:    \n",
    "            startdate = reg.strip('\\n')\n",
    "            startdate = startdate.replace('\\n', ' ')\n",
    "        \n",
    "        xml_file.write('\\t'+'<start_date>'+startdate+'</start_date>\\n') # writing the xml file\n",
    "        json_dict['start_date'] = startdate # storing in the json dict for json file\n",
    "        \n",
    "        #group10(application_deadline)\n",
    "        reg=regex_part(str_deadline, each)\n",
    "        if reg in('',' ','\\n'):\n",
    "            deadline = 'N.A.'\n",
    "        else:    \n",
    "            deadline = reg.strip('\\n')\n",
    "            deadline = deadline.replace('\\n', ' ')\n",
    "        \n",
    "        xml_file.write('\\t'+'<application_deadline>'+deadline+'</application_deadline>\\n')\n",
    "        json_dict['application_deadline'] = deadline # storing in the json dict for json file\n",
    "        \n",
    "        #group11(about_company)\n",
    "        reg=regex_part(str_abtcompny, each)\n",
    "        if reg in('',' ','\\n'):\n",
    "            abtcompny = 'N.A.'\n",
    "        else:    \n",
    "            abtcompny = reg.strip('\\n')\n",
    "            abtcompny = abtcompny.replace('\\n', ' ')\n",
    "        \n",
    "        xml_file.write('\\t'+'<about_company>'+abtcompny+'</about_company>\\n') # writing the xml file\n",
    "        json_dict['about_company'] = abtcompny # storing in the json dict for json file\n",
    "        \n",
    "        xml_file.write('\\t'+'</listing>'+'\\n')\n",
    "        xml_file.write('</listings>\\n')  \n",
    "         \n",
    "        list_data.append(json_dict)\n",
    "        \n",
    "json_data = {'listings': {'listing': list_data}}\n",
    "json.dump(json_data, json_file, indent = 4 * ' ') # writing the json file\n",
    "        \n",
    "        \n",
    "xml_file.close() # close xml file\n",
    "json_file.close() # close json file\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the Open tags in the files\n",
    "xml_file = open('29325293.xml','r')  # xml file open\n",
    "json_file = open('29325293.json','r')    # json file open\n",
    "\n",
    "f = xml_file.read()\n",
    "g = json_file.read()\n",
    "if 'OPEN TO/' in f:\n",
    "    f = f.replace('OPEN TO/', '')\n",
    "    g = g.replace('OPEN TO/', '')\n",
    "\n",
    "if 'REMUNERATION/' in f:\n",
    "    f = f.replace('REMUNERATION/', '')\n",
    "    g = g.replace('REMUNERATION/', '')\n",
    "\n",
    "if 'OPEN TO/' in f:\n",
    "    f = f.replace('OPEN TO/', '')\n",
    "    g = g.replace('OPEN TO/', '')\n",
    "\n",
    "if 'START DATE/' in f:\n",
    "    f = f.replace('START DATE/', '')  \n",
    "    g = g.replace('START DATE/', '')\n",
    "\n",
    "if 'ABOUT PROGRAM/' in f:\n",
    "    f = f.replace('ABOUT PROGRAM/', '') \n",
    "    g = g.replace('ABOUT PROGRAM/', '') \n",
    "\n",
    "xml_file.close()\n",
    "json_file.close()\n",
    "\n",
    "xml_file = open('29325293.xml','w')\n",
    "json_file = open('29325293.json','w')\n",
    "\n",
    "xml_file.write(f)\n",
    "json_file.write(g)\n",
    "\n",
    "xml_file.close()\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "With the help of regex, we have separated the unstructured data into two files, JSON and XML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of job listings are 31403\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of job listings are\", len(str1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
